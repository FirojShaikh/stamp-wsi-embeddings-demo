{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "STAMP_WSI_Embeddings_Demo.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt0sgbHRy3jR"
      },
      "source": [
        "# STAMP Demo — Tile Embedding Extraction from WSIs"
      ],
      "id": "nt0sgbHRy3jR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAyYxVpjy3jT"
      },
      "source": [
        "## 1. Environment Setup"
      ],
      "id": "jAyYxVpjy3jT"
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Helper function to run commands and capture errors\n",
        "def run_command(cmd):\n",
        "    try:\n",
        "        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error in command '{cmd}': {e.stderr}\")\n",
        "        raise\n",
        "\n",
        "print(\"Setting up environment...\")\n",
        "\n",
        "# 1. Verify GPU\n",
        "print(\"Checking GPU...\")\n",
        "try:\n",
        "    run_command(\"nvidia-smi\")\n",
        "except Exception as e:\n",
        "    print(\"GPU check failed. Ensure GPU is enabled (Runtime → Change runtime type → GPU).\")\n",
        "\n",
        "# 2. Install dependencies with fallback\n",
        "print(\"Installing pandas and numpy...\")\n",
        "run_command(\"pip install -q pandas==2.2.2 numpy==1.26.4 --force-reinstall --no-warn-conflicts\")\n",
        "\n",
        "print(\"Updating apt and installing system packages...\")\n",
        "run_command(\"apt-get update -qq\")\n",
        "run_command(\"apt-get install -y libgl1-mesa-glx libglib2.0-0\")\n",
        "\n",
        "print(\"Installing Python packages...\")\n",
        "try:\n",
        "    run_command(\"pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu124\")\n",
        "    run_command(\"pip install -q git+https://github.com/KatherLab/STAMP.git h5py matplotlib pillow openslide-python scikit-image --retries 3\")\n",
        "except Exception as e:\n",
        "    print(\"STAMP install failed. Retrying with verbose output...\")\n",
        "    run_command(\"pip install -v -q git+https://github.com/KatherLab/STAMP.git h5py matplotlib pillow openslide-python scikit-image --retries 3\")\n",
        "\n",
        "# 3. Mount Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(f\"Drive mount failed: {e}\")\n",
        "    print(\"Please authenticate when prompted and paste the code.\")\n",
        "\n",
        "# 4. Setup output directory and verify GPU\n",
        "import os, matplotlib.pyplot as plt, h5py, numpy as np, torch\n",
        "os.makedirs(\"/content/drive/MyDrive/STAMP_demo_features\", exist_ok=True)\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "print(\"Environment setup complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6__xvlf0Bcvs",
        "outputId": "c71ace32-a349-4e93-d652-9555027122b1"
      },
      "id": "6__xvlf0Bcvs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment...\n",
            "Checking GPU...\n",
            "Wed Oct 15 04:09:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             12W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "Installing pandas and numpy...\n",
            "\n",
            "Updating apt and installing system packages...\n",
            "\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.6).\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "\n",
            "Installing Python packages...\n",
            "\n",
            "\n",
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "GPU: Tesla T4\n",
            "Environment setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using WSI from /content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT\n",
        "!ls -lh \"/content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT/TCGA-2A-A8VT-01Z-00-DX1.F2CD9AAB-7B40-46A4-832B-1279A8A77737.svs\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYXTqvf0EI6G",
        "outputId": "7e3025cb-c8e0-4a4c-eedb-59231dd685b0"
      },
      "id": "zYXTqvf0EI6G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1.5G Jun  8  2024 /content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT/TCGA-2A-A8VT-01Z-00-DX1.F2CD9AAB-7B40-46A4-832B-1279A8A77737.svs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl1-aCgVy3jV"
      },
      "source": [
        "## 2. Create Config File"
      ],
      "id": "Tl1-aCgVy3jV"
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Config File\n",
        "%%bash\n",
        "cat > config.yaml <<EOF\n",
        "preprocessing:\n",
        "  output_dir: \"/content/drive/MyDrive/STAMP_demo_features\"\n",
        "  wsi_dir: \"/content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT\"\n",
        "\n",
        "  # Other possible values are \"mahmood-uni\" and \"mahmood-conch\"\n",
        "  extractor: \"ctranspath\"\n",
        "\n",
        "  # Having a cache dir will speed up extracting features multiple times,\n",
        "  # e.g. with different feature extractors.\n",
        "  # Optional.\n",
        "  # cache_dir: \"/absolute/path/to/stamp-test-experiment/../cache\"\n",
        "  # If you do not want to use a cache,\n",
        "  # change the cache dir to the following:\n",
        "  cache_dir: \"/content/drive/MyDrive/STAMP_demo_features/cache\"\n",
        "\n",
        "  # Device to run feature extraction on.\n",
        "  # Set this to \"cpu\" if you do not have a CUDA-capable GPU.\n",
        "  device: \"cuda\"\n",
        "\n",
        "  # How many workers to use for tile extraction.  Should be less or equal to\n",
        "  # the number of cores of your system.\n",
        "  max_workers: 8\n",
        "\n",
        "EOF\n",
        "\n",
        "cat config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-HDIFLcEVRM",
        "outputId": "c3244f36-95eb-4ad1-ec33-c8f5de80b5aa"
      },
      "id": "x-HDIFLcEVRM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing:\n",
            "  output_dir: \"/content/drive/MyDrive/STAMP_demo_features\"\n",
            "  wsi_dir: \"/content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT\"\n",
            "\n",
            "  # Other possible values are \"mahmood-uni\" and \"mahmood-conch\"\n",
            "  extractor: \"ctranspath\"\n",
            "\n",
            "  # Having a cache dir will speed up extracting features multiple times,\n",
            "  # e.g. with different feature extractors.\n",
            "  # Optional.\n",
            "  # cache_dir: \"/absolute/path/to/stamp-test-experiment/../cache\"\n",
            "  # If you do not want to use a cache,\n",
            "  # change the cache dir to the following:\n",
            "  cache_dir: null\n",
            "\n",
            "  # Device to run feature extraction on.\n",
            "  # Set this to \"cpu\" if you do not have a CUDA-capable GPU.\n",
            "  device: \"cuda\"\n",
            "\n",
            "  # How many workers to use for tile extraction.  Should be less or equal to\n",
            "  # the number of cores of your system.\n",
            "  max_workers: 8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maTuwgLUFOMj",
        "outputId": "23c2b262-a13c-4bd4-aa27-fc458c607fdc"
      },
      "id": "maTuwgLUFOMj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN3-ricmy3jV"
      },
      "source": [
        "## 3. Preprocess (Extract Tiles)"
      ],
      "id": "aN3-ricmy3jV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbI3OoL2y3jV",
        "outputId": "5724ccf5-45c6-4d11-edf0-45afb3992858"
      },
      "source": [
        "!stamp --config config.yaml preprocess"
      ],
      "id": "YbI3OoL2y3jV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-15 04:32:09,707\tINFO\tusing the following configuration:\n",
            "brightness_cutoff: 240\n",
            "cache_dir: null\n",
            "cache_tiles_ext: jpg\n",
            "canny_cutoff: 0.02\n",
            "default_slide_mpp: null\n",
            "device: cuda\n",
            "extractor: ctranspath\n",
            "generate_hash: true\n",
            "max_workers: 8\n",
            "output_dir: /content/drive/MyDrive/STAMP_demo_features\n",
            "tile_size_px: 224\n",
            "tile_size_um: 256.0\n",
            "wsi_dir: /content/drive/MyDrive/WSI_Shared_Folder/output_imgs/high_risk/TCGA-2A-A8VT\n",
            "wsi_list: null\n",
            "\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=1DoDx_70_TLj98gTf6YTXnu4tFhsFocDX&export=download\n",
            "From (redirected): https://drive.google.com/uc?id=1DoDx_70_TLj98gTf6YTXnu4tFhsFocDX&export=download&confirm=t&uuid=8f73572d-d792-4c5c-b9d9-be0527dae21a\n",
            "To: /root/.cache/stamp/ctranspath.pth\n",
            "100% 111M/111M [00:02<00:00, 50.5MB/s]\n",
            "2025-10-15 04:32:17,556\tINFO\tUsing extractor ctranspath\n",
            "TCGA-2A-A8VT-01Z-00-DX1.F2CD9AAB-7B40-46A4-832B-1279A8A77737.svs:   0% 0/1 [00:00<?, ?it/s]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [06:46, 406.15s/it]\u001b[A\n",
            "2it [07:14, 184.12s/it]\u001b[A\n",
            "3it [08:11, 125.88s/it]\u001b[A\n",
            "4it [08:51, 91.99s/it] \u001b[A\n",
            "5it [09:18, 68.42s/it]\u001b[A\n",
            "6it [09:39, 52.47s/it]\u001b[A\n",
            "7it [09:44, 37.07s/it]\u001b[A\n",
            "8it [09:56, 29.00s/it]\u001b[A\n",
            "9it [10:03, 22.15s/it]\u001b[A\n",
            "10it [10:07, 16.36s/it]\u001b[A\n",
            "11it [10:10, 12.51s/it]\u001b[A\n",
            "12it [10:18, 10.87s/it]\u001b[A\n",
            "13it [10:24,  9.39s/it]\u001b[A\n",
            "14it [10:32,  9.14s/it]\u001b[A\n",
            "15it [10:37,  7.73s/it]\u001b[A\n",
            "16it [10:39,  6.00s/it]\u001b[A\n",
            "17it [10:42,  5.22s/it]\u001b[A\n",
            "18it [10:46,  4.76s/it]\u001b[A\n",
            "19it [10:53,  5.47s/it]\u001b[A\n",
            "20it [10:55,  4.51s/it]\u001b[A\n",
            "21it [11:02,  5.34s/it]\u001b[A\n",
            "22it [11:12,  6.53s/it]\u001b[A\n",
            "23it [11:19,  6.69s/it]\u001b[A\n",
            "24it [11:23,  5.91s/it]\u001b[A\n",
            "25it [11:27,  5.51s/it]\u001b[A\n",
            "26it [11:36,  6.56s/it]\u001b[A\n",
            "27it [11:40,  5.56s/it]\u001b[A\n",
            "28it [11:43,  4.97s/it]\u001b[A\n",
            "29it [11:48,  4.87s/it]\u001b[A\n",
            "30it [11:56,  6.00s/it]\u001b[A\n",
            "31it [12:05,  6.70s/it]\u001b[A\n",
            "32it [12:11,  6.62s/it]\u001b[A\n",
            "33it [12:15,  5.73s/it]\u001b[A\n",
            "34it [12:22,  6.17s/it]\u001b[A\n",
            "35it [12:27,  5.78s/it]\u001b[A\n",
            "36it [12:34,  6.14s/it]\u001b[A\n",
            "37it [12:39,  5.81s/it]\u001b[A\n",
            "38it [12:48,  6.71s/it]\u001b[A\n",
            "39it [12:50,  5.27s/it]\u001b[A\n",
            "40it [12:53,  4.83s/it]\u001b[A\n",
            "41it [12:56,  4.06s/it]\u001b[A\n",
            "42it [12:59,  3.96s/it]\u001b[A\n",
            "43it [13:04,  4.26s/it]\u001b[A\n",
            "44it [13:11,  4.83s/it]\u001b[A\n",
            "45it [13:14,  4.36s/it]\u001b[A\n",
            "46it [13:17,  4.00s/it]\u001b[A\n",
            "47it [13:20,  3.77s/it]\u001b[A\n",
            "48it [13:26,  4.28s/it]\u001b[A\n",
            "49it [13:29,  3.98s/it]\u001b[A\n",
            "50it [13:31,  3.37s/it]\u001b[A\n",
            "51it [13:36,  3.86s/it]\u001b[A\n",
            "52it [13:40,  3.83s/it]\u001b[A\n",
            "53it [13:46,  4.55s/it]\u001b[A\n",
            "54it [13:48,  3.80s/it]\u001b[A\n",
            "55it [13:53,  4.08s/it]\u001b[A\n",
            "56it [13:56,  3.94s/it]\u001b[A\n",
            "57it [13:59,  3.48s/it]\u001b[A\n",
            "58it [14:02,  3.43s/it]\u001b[A\n",
            "59it [14:08,  4.09s/it]\u001b[A\n",
            "60it [14:10,  3.52s/it]\u001b[A\n",
            "61it [14:14,  3.62s/it]\u001b[A\n",
            "62it [14:16,  3.23s/it]\u001b[A\n",
            "63it [14:20,  3.54s/it]\u001b[A\n",
            "64it [14:24,  3.58s/it]\u001b[A\n",
            "65it [14:26,  3.20s/it]\u001b[A\n",
            "66it [14:32,  3.87s/it]\u001b[A\n",
            "67it [14:34,  3.43s/it]\u001b[A\n",
            "68it [14:38,  3.57s/it]\u001b[A\n",
            "69it [14:41,  3.52s/it]\u001b[A\n",
            "70it [14:44,  3.21s/it]\u001b[A\n",
            "71it [14:47,  3.05s/it]\u001b[A\n",
            "72it [14:50,  3.03s/it]\u001b[A\n",
            "73it [14:54,  3.39s/it]\u001b[A\n",
            "74it [14:58,  3.54s/it]\u001b[A\n",
            "75it [15:01,  3.60s/it]\u001b[A\n",
            "76it [15:06,  3.89s/it]\u001b[A\n",
            "77it [15:06,  2.86s/it]\u001b[A\n",
            "TCGA-2A-A8VT-01Z-00-DX1.F2CD9AAB-7B40-46A4-832B-1279A8A77737.svs: 100% 1/1 [15:33<00:00, 933.33s/it]\n"
          ]
        }
      ]
    }
  ]
}